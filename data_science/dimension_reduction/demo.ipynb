{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the requriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip install numpy\n",
    "! pip install scikit-learn\n",
    "# ! pip install torch==1.10.1+cu102\n",
    "! pip install umap-learn\n",
    "! pip install plotly\n",
    "! pip install scikit-dimension\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset open-source packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "Dataset = 'CIFAR10'\n",
    "\n",
    "if Dataset == 'MNIST':\n",
    "    digit_num = 10\n",
    "    digits = datasets.load_digits(n_class=digit_num)\n",
    "    X, y = digits.data, digits.target\n",
    "elif Dataset == 'CIFAR10':\n",
    "    cifar10 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "    X, y = cifar10.data.transpose(0,3,1,2)[:2000], np.array(cifar10.targets)[:2000]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter and keep the same number of samples for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the same number of samples for each class\n",
    "labels, sample_num = np.unique(y, return_counts=True)\n",
    "sample_num = np.min(sample_num)\n",
    "X = np.concatenate([X[y == label][:sample_num] for label in labels])\n",
    "y = np.concatenate([y[y == label][:sample_num] for label in labels])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrix: **score** and **time cost** of the vectors matching by nearest k neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def calculate_dist(x, y, method='Euclidean', p=3):\n",
    "    \"\"\"\n",
    "    Calculate the distance between x and y\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'Euclidean':\n",
    "        dist = np.sqrt(np.sum(np.square(x - y)))\n",
    "    elif method == 'Manhattan':\n",
    "        dist = np.sum(np.abs(x - y))\n",
    "    elif method == 'Cosine':\n",
    "        dist = np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "        dist = 1 - dist  # ensure larger distance means less similarity\n",
    "    elif method == 'Chebyshev':\n",
    "        dist = np.max(np.abs(x - y))\n",
    "    elif method == 'Minkowski':\n",
    "        dist = np.power(np.sum(np.power(np.abs(x - y), p)), 1 / p)\n",
    "    else:\n",
    "        raise ValueError('Invalid distance method')\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def nearest_k_neighbors(X, Y, k=10, method='Euclidean', p=3):\n",
    "    \"\"\"\n",
    "    Evaluate the nearest k neighbors of X in Y\n",
    "    \"\"\"\n",
    "\n",
    "    dist = np.zeros(Y.shape[0])\n",
    "    for i in range(Y.shape[0]):\n",
    "        dist[i] = calculate_dist(X, Y[i], method=method, p=p)\n",
    "    idx = np.argsort(dist)[:k]\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "def evaluate_similarity_matching(vectors, labels, N, m=20, method='Euclidean', p=3):\n",
    "    \"\"\"\n",
    "    Evaluate the similarity of the vectors by nearest k neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    score = 0\n",
    "    time_cost = 0\n",
    "    random_idx = np.random.choice(vectors.shape[0], m, replace=False)\n",
    "    for i in random_idx:\n",
    "        start_t = time.perf_counter()\n",
    "        idx = nearest_k_neighbors(vectors[i], vectors, k=N, method=method, p=p)\n",
    "        end_t = time.perf_counter()\n",
    "        score += np.sum(labels[idx] == labels[i])\n",
    "        time_cost += end_t - start_t\n",
    "    score /= (m * N)\n",
    "    time_cost /= m\n",
    "\n",
    "    return score, time_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "dist = 'Cosine'\n",
    "score_original, t_original = evaluate_similarity_matching(X, y, N=sample_num, m=m, method=dist, p=3)\n",
    "score_original, t_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension Estimator: identify the intrinsic dimension of embedding space (Ref: scikit-dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skdim\n",
    "\n",
    "\n",
    "class Estimater(object):\n",
    "    \"\"\"Intrinsic dimension estimation class for embedding vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method):\n",
    "\n",
    "        assert method in ['MLE', 'MADA', 'MiND',\n",
    "                          'CorrInt', 'TwoNN', 'TLE', 'MOM', 'FisherS']\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        \"\"\"Fit the estimator from the given data.\n",
    "        \"\"\"\n",
    "        if self.method == 'MLE':\n",
    "            self.estimator_ = skdim.id.MLE(**kwargs)\n",
    "        elif self.method == 'MADA':\n",
    "            self.estimator_ = skdim.id.MADA(**kwargs)\n",
    "        elif self.method == 'MiND':\n",
    "            self.estimator_ = skdim.id.MiND_ML(**kwargs)\n",
    "        elif self.method == 'DANCo':\n",
    "            self.estimator_ = skdim.id.DANCo(**kwargs)\n",
    "        elif self.method == 'CorrInt':\n",
    "            self.estimator_ = skdim.id.CorrInt(**kwargs)\n",
    "        elif self.method == 'TwoNN':\n",
    "            self.estimator_ = skdim.id.TwoNN(**kwargs)\n",
    "        elif self.method == 'TLE':\n",
    "            self.estimator_ = skdim.id.TLE(**kwargs)\n",
    "        elif self.method == 'MOM':\n",
    "            self.estimator_ = skdim.id.MOM(**kwargs)\n",
    "        elif self.method == 'FisherS':\n",
    "            self.estimator_ = skdim.id.FisherS(**kwargs)\n",
    "        elif self.method == 'ESS':\n",
    "            self.estimator_ = skdim.id.ESS(**kwargs)\n",
    "        self.estimator_.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform the given data.\n",
    "        \"\"\"\n",
    "        return self.estimator_.transform(X)\n",
    "\n",
    "    def fit_transform(self, X, **kwargs):\n",
    "        \"\"\"Fit the estimator from the given data and transform it.\n",
    "        \"\"\"\n",
    "        return self.fit(X, **kwargs).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dim = []\n",
    "for algo in ['MLE', 'MADA', 'MiND', 'CorrInt','TwoNN', 'TLE', 'MOM', 'FisherS']:\n",
    "    estimater = Estimater(method=algo)\n",
    "    dim.append(estimater.fit(X).transform(X))\n",
    "    print(algo, f'{dim[-1]:.1f}')\n",
    "print('Mean', f'{np.mean(dim):.1f}')\n",
    "\n",
    "n_component = round(np.mean(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import towhee\n",
    "ae = towhee.ops.dimension_reduction.ae(\n",
    "    n_latent=n_component,\n",
    "    n_encoders=[X.shape[-1], 32],\n",
    "    n_decoders=[32, X.shape[-1]],\n",
    "    activation=\"relu\",\n",
    "    max_epoch=1000,\n",
    "    patience=100,\n",
    "    device=\"cpu\"\n",
    ").get_op()\n",
    "\n",
    "X_reduced_ae = ae.fit_transform(X)\n",
    "score_reduced_ae, t_reduced_ae = evaluate_similarity_matching(X_reduced_ae, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pca = towhee.ops.dimension_reduction.pca(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_pca = pca.fit_transform(X)\n",
    "score_reduced_pca, t_reduced_pca = evaluate_similarity_matching(X_reduced_pca, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "isomap = towhee.ops.dimension_reduction.isomap(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_isomap = isomap.fit_transform(X)\n",
    "score_reduced_isomap, t_reduced_isomap = evaluate_similarity_matching(X_reduced_isomap, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lle = towhee.ops.dimension_reduction.lle(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_lle = lle.fit_transform(X)\n",
    "score_reduced_lle, t_reduced_lle = evaluate_similarity_matching(X_reduced_lle, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mds = towhee.ops.dimension_reduction.mds(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_mds = mds.fit_transform(X)\n",
    "score_reduced_mds, t_reduced_mds = evaluate_similarity_matching(X_reduced_mds, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "se = towhee.ops.dimension_reduction.se(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_se = se.fit_transform(X)\n",
    "score_reduced_se, t_reduced_se = evaluate_similarity_matching(X_reduced_se, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "umap = towhee.ops.dimension_reduction.umap(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_umap = umap.fit_transform(X)\n",
    "score_reduced_umap, t_reduced_umap = evaluate_similarity_matching(X_reduced_umap, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tsne = towhee.ops.dimension_reduction.tsne(\n",
    "    n_components=n_component,\n",
    ").get_op()\n",
    "X_reduced_tsne = tsne.fit_transform(X)\n",
    "score_reduced_tsne, t_reduced_tsne = evaluate_similarity_matching(X_reduced_tsne, y, N=sample_num, m=m, method=dist, p=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization:\n",
    "\n",
    "1. plot_mix()\n",
    "2. plot_dim_reduct_acc_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def _get_color(color, color_type):\n",
    "\n",
    "    if color_type == 'continuous':\n",
    "        color = color.astype(np.float32)\n",
    "    elif color_type == 'discrete':\n",
    "        color = color.astype(str)\n",
    "    else:\n",
    "        raise ValueError('Invalid type of the color.')\n",
    "\n",
    "    return color\n",
    "\n",
    "\n",
    "def plot_mixed(data, color, marker_size, title, zoom, score1, score2, t1, t2, dim1, dim2, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot mixed figure of '2D scatter matrix', '3D scatter' and 'Bar of comparsion'\n",
    "    \"\"\"\n",
    "\n",
    "    assert data.shape[-1] >= 5, 'The number of components must be greater than or equal to 5.'\n",
    "\n",
    "    # n_components = data.shape[1]\n",
    "    n_components = dim2\n",
    "    bar_width = round(np.sqrt(n_components))\n",
    "    bar_height = round(np.floor((n_components-bar_width)/3))\n",
    "\n",
    "    specs = [[] for _ in range(n_components)]\n",
    "    subfig_title = ['' for _ in range(n_components*(n_components+bar_width))]\n",
    "    subfig_title[(n_components-3*bar_height+1) *\n",
    "                 n_components + 2-1] = 'Dimension of vectors'\n",
    "    subfig_title[(n_components-2*bar_height+1)*n_components +\n",
    "                 3-1] = 'Score of vector matching'\n",
    "    subfig_title[(n_components-bar_height+1)*n_components +\n",
    "                 4-1] = 'Time cost of vector matching'\n",
    "    subfig_title[n_components] = '3D scatter'\n",
    "    subfig_title[round(np.floor(n_components/2))] = '2D scatter matrix'\n",
    "\n",
    "    for i in range(n_components):\n",
    "        if i == 0:\n",
    "            specs[i] = [{'type': 'xy'}]*n_components + [{'type': 'scene',\n",
    "                                                         'rowspan': bar_width, 'colspan': bar_width}] + [None]*(bar_width-1)\n",
    "        elif i in range(n_components-3*bar_height, n_components, bar_height):\n",
    "            specs[i] = [{'type': 'xy'}]*n_components + [{'type': 'bar',\n",
    "                                                         'rowspan': bar_height, 'colspan': bar_width}] + [None]*(bar_width-1)\n",
    "        else:\n",
    "            specs[i] = [{'type': 'xy'}]*n_components+[None]*bar_width\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_components, cols=n_components+bar_width,\n",
    "        specs=specs,\n",
    "        horizontal_spacing=0.045,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=subfig_title,\n",
    "    )\n",
    "\n",
    "    color = _get_color(color, 'continuous')\n",
    "    text = _get_color(color, 'discrete')\n",
    "\n",
    "    # 2d scatter matrix\n",
    "    for i in range(n_components):\n",
    "        for j in range(n_components):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data[:, i],\n",
    "                    y=data[:, j],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        color=color,\n",
    "                        size=marker_size,\n",
    "                        colorscale='Viridis',\n",
    "                        showscale=True\n",
    "                    ),\n",
    "                    name='2D scatter matrix',\n",
    "                    showlegend=False,\n",
    "                    text=text,\n",
    "                ),\n",
    "                row=i+1, col=j+1,\n",
    "            )\n",
    "\n",
    "    # 3d scatter\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=data[:, 0],\n",
    "            y=data[:, 1],\n",
    "            z=data[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color=color,\n",
    "                size=marker_size,\n",
    "                colorscale='Viridis',\n",
    "                showscale=True\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            name='3D scatter',\n",
    "            text=text\n",
    "        ),\n",
    "        row=1, col=n_components+1,\n",
    "    )\n",
    "\n",
    "    # bar\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['Before', 'After'],\n",
    "            y=[dim1, dim2],\n",
    "            name='Dimension of vectors',\n",
    "            text=[str(dim1), str(dim2)],\n",
    "            textposition='auto',\n",
    "            showlegend=False,\n",
    "            marker=dict(color=['#a8cee3', '#f3be78']),\n",
    "        ),\n",
    "        row=n_components-3*bar_height+1, col=n_components+1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['Before', 'After'],\n",
    "            y=[score1, score2],\n",
    "            name='Score of vector matching',\n",
    "            text=[f'{score1*100:.2f}%', f'{score2*100:.2f}%'],\n",
    "            textposition='auto',\n",
    "            showlegend=False,\n",
    "            marker=dict(color=['#a8cee3', '#f3be78']),\n",
    "        ),\n",
    "        row=n_components-2*bar_height+1, col=n_components+1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['Before', 'After'],\n",
    "            y=[t1, t2],\n",
    "            name='Time cost of vector matching',\n",
    "            text=[f'{t1*1e3:.2f}ms', f'{t2*1e3:.2f}ms'],\n",
    "            textposition='auto',\n",
    "            showlegend=False,\n",
    "            marker=dict(color=['#a8cee3', '#f3be78']),\n",
    "        ),\n",
    "        row=n_components-bar_height+1, col=n_components+1,\n",
    "    )\n",
    "\n",
    "    # layout\n",
    "    ratio = (n_components-5)/n_components  # based on 5*5\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        width=int(zoom*800*(1+ratio)*(1+bar_width/n_components)),\n",
    "        height=int(zoom*800*(1+ratio)),\n",
    "    )\n",
    "\n",
    "    # adjust axes\n",
    "    for i in range(n_components):\n",
    "        for j in range(n_components):\n",
    "            fig.update_xaxes(title_text=f'dim_{i}', row=i+1, col=j+1,\n",
    "                             title_standoff=0, title_font=dict(size=9.5), tickfont=dict(size=9.5))\n",
    "            fig.update_yaxes(title_text=f'dim_{j}', row=i+1, col=j+1,\n",
    "                             title_standoff=0, title_font=dict(size=9.5), tickfont=dict(size=9.5))\n",
    "    fig.update_scenes(\n",
    "        xaxis_title_text=f'dim_{0}',\n",
    "        yaxis_title_text=f'dim_{1}',\n",
    "        zaxis_title_text=f'dim_{2}',\n",
    "        xaxis_title_font=dict(size=9.5),\n",
    "        yaxis_title_font=dict(size=9.5),\n",
    "        zaxis_title_font=dict(size=9.5),\n",
    "        xaxis_tickfont=dict(size=9.5),\n",
    "        yaxis_tickfont=dict(size=9.5),\n",
    "        zaxis_tickfont=dict(size=9.5),\n",
    "        row=1, col=n_components+1,\n",
    "    )\n",
    "    for i in range(n_components-3*bar_height, n_components, bar_height):\n",
    "        fig.update_xaxes(title_font=dict(size=9.5), tickfont=dict(\n",
    "            size=9.5), row=i, col=n_components+1, title_standoff=0)\n",
    "        if i == 0:\n",
    "            fig.update_yaxes(title_font=dict(size=9.5), tickfont=dict(size=9.5), range=[\n",
    "                             0, 1], row=i, col=n_components+1, title_standoff=0)\n",
    "        else:\n",
    "            fig.update_yaxes(title_font=dict(size=9.5), tickfont=dict(\n",
    "                size=9.5), row=i, col=n_components+1, title_standoff=0)\n",
    "\n",
    "    fig.update_traces(marker=dict(line=dict(width=0.1)))\n",
    "    \n",
    "    \n",
    "def plot_dim_reduct_acc_comparison(names, scores, dist, score_original):\n",
    "    \"\"\"\n",
    "    Plot bar figure of dimension reduction accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=names,\n",
    "        y=scores,\n",
    "        text=[f'{score*100:.2f}%' for score in scores],\n",
    "        textposition=\"auto\",\n",
    "    )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"Accuracy of similarity matching ({dist})\",\n",
    "        xaxis_title=\"Method\",\n",
    "        yaxis_title=\"Accuracy\",\n",
    "        width=800,\n",
    "        height=500,\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        y0=score_original,\n",
    "        x1=8.5,\n",
    "        y1=score_original,\n",
    "        line=dict(\n",
    "            color=\"Red\",\n",
    "            width=2,\n",
    "            dash=\"dashdot\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mixed(data=X_reduced_umap,\n",
    "    color=y,\n",
    "    marker_size=2,\n",
    "    title=\"UMAP\",\n",
    "    zoom=0.65,\n",
    "    label='digit',\n",
    "    score1=score_original,\n",
    "    score2=score_reduced_umap,\n",
    "    t1=t_original,\n",
    "    t2=t_reduced_umap,\n",
    "    dim1=X.shape[1],\n",
    "    dim2=n_component,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Original\", \"AE\", \"PCA\", \"LLE\", \"Isomap\", \"MDS\", \"SE\", \"UMAP\", \"TSNE\"]\n",
    "scores = [score_original, score_reduced_ae, score_reduced_pca, score_reduced_lle, score_reduced_isomap, score_reduced_mds, score_reduced_se, score_reduced_umap, score_reduced_tsne]\n",
    "\n",
    "plot_dim_reduct_acc_comparison(names, scores, dist=dist, score_original=score_original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.10-py38-cuda10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
