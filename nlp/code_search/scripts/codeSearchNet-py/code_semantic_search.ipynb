{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pymilvus==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connectings to Milvus\n",
    "from pymilvus import connections, utility\n",
    "connections.connect(host='192.168.103.57', port='19530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message='')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TABLE_NAME = \"text_collection\"\n",
    "if utility.has_collection(TABLE_NAME):\n",
    "    utility.drop_collection(TABLE_NAME)\n",
    "field_name = \"embedding\"\n",
    "from pymilvus import Collection, CollectionSchema, FieldSchema, DataType\n",
    "pk = FieldSchema(name=\"id\", dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=True)\n",
    "field = FieldSchema(name=field_name, dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=512)\n",
    "schema = CollectionSchema(fields=[pk, field], description=\"code search\")\n",
    "collection = Collection(name=TABLE_NAME, schema=schema)\n",
    "index_param = {\n",
    "        \"metric_type\":\"IP\",\n",
    "        \"index_type\":\"IVF_SQ8\",\n",
    "        \"params\":{\"nlist\":1024}\n",
    "    }\n",
    "collection.create_index(field_name=field_name, index_params=index_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get code embedding and save to disk(dataset: codeSearchNet-py-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash get_code_embed.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load code embedding from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "code_embed_path = '../../tmp_ex0/code.embeddings.npy'\n",
    "code_embed = np.load(code_embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "em =list(code_embed)\n",
    "mr = collection.insert([em])\n",
    "ids = mr.primary_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2code = dict()\n",
    "code_path = '../../data/codeSearchNet-py/test/code.original_subtoken'\n",
    "with open(code_path) as f:\n",
    "    lines = f.readlines()\n",
    "    assert len(lines) == len(ids)\n",
    "    for line, id in zip(lines, ids):\n",
    "        code = line.strip()\n",
    "        id2code[id] = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2code = dict()\n",
    "doc_path = '../../data/codeSearchNet-py/test/doc.original'\n",
    "with open(code_path) as f1, open(doc_path) as f2:\n",
    "    code_lines = f1.readlines()\n",
    "    doc_lines = f2.readlines()\n",
    "    assert len(code_lines) == len(doc_lines)\n",
    "    for code, doc in zip(code_lines, doc_lines):\n",
    "        doc2code[doc.strip()] = code.strip()\n",
    "if len(doc2code) < len(doc_lines):\n",
    "    print('There are duplicate docs, keep only one of them!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import towhee\n",
    "search_text = ['Check for message on subscribed channels and write to xcom the message with key message',\n",
    "               'Get a pandas dataframe from a sql query .']\n",
    "search_embeds = (\n",
    "        towhee.dc(search_text) \\\n",
    "              .image_text_embedding.clip(model_name='clip_vit_b32', modality='text') \\\n",
    "              .tensor_normalize()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = np.dot(code_embed, search_embeds[0])\n",
    "# scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(zip(scores.tolist(), ids), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
    "collection.load()\n",
    "search_embeds = [embed.tolist() for embed in search_embeds]\n",
    "results = collection.search(search_embeds, field_name, param=search_params, limit=8, expr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search text:  Check for message on subscribed channels and write to xcom the message with key message\n",
      "--------------------------------------------------------------------------------\n",
      "ground truth:\n",
      "def poke self context self log info 'Redis Pub Sub Sensor checking for message on channels %s' self channels message self pubsub get message self log info 'Message %s from channel %s' message self channels if message and message [ 'type' ] 'message' context [ 'ti' ] xcom push key 'message' value message self pubsub unsubscribe self channels return True return False\n",
      "--------------------------------------------------------------------------------\n",
      "                                      search results  distance\n",
      "0  def poke self context self log info 'Redis Pub...  0.177596\n",
      "1  def unserialize self msg list content True cop...  0.172991\n",
      "2  def subscribe To Device Commands self type Id ...  0.170548\n",
      "3  def sub channel self if self sub channel is No...  0.170207\n",
      "4  def giving up self message logger warning '[%s...  0.167349\n",
      "5  def publish pyin self code parent execution co...  0.166594\n",
      "6  def subscribe self self stream setsockopt zmq ...  0.162352\n",
      "7  async def subscribe self channels ws channels ...  0.159941\n",
      "================================================================================\n",
      "\n",
      "search text:  Get a pandas dataframe from a sql query .\n",
      "--------------------------------------------------------------------------------\n",
      "ground truth:\n",
      "def get pandas df self hql parameters None import pandas cursor self get cursor try cursor execute self strip sql hql parameters data cursor fetchall except Database Error as e raise Presto Exception self get pretty exception message e column descriptions cursor description if data df pandas Data Frame data df columns [ c [ 0 ] for c in column descriptions ] else df pandas Data Frame return df\n",
      "--------------------------------------------------------------------------------\n",
      "                                      search results  distance\n",
      "0  def to pandas df self column names None select...  0.334371\n",
      "1  def get pandas df self sql parameters None imp...  0.334254\n",
      "2  def get dataframe self if pd is None raise Imp...  0.331672\n",
      "3  def get dataframe self tickers start Date None...  0.327836\n",
      "4  def get pandas df self hql parameters None imp...  0.327455\n",
      "5  def get pandas df self hql schema 'default' im...  0.325233\n",
      "6  def dt minute x import pandas as pd return pd ...  0.321872\n",
      "7  def dt dayofyear x import pandas as pd return ...  0.315181\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in range(len(search_text)):\n",
    "    print('search text: ', search_text[i])\n",
    "    print('-'*80)\n",
    "    print('ground truth:')\n",
    "    print(doc2code[search_text[i]])\n",
    "    print('-'*80)\n",
    "    table = dict()\n",
    "    table['search results'] = [id2code[result.id] for result in results[i]]\n",
    "    table['distance'] = [result.distance for result in results[i]]\n",
    "    df = pd.DataFrame(table)\n",
    "    print(df)\n",
    "    print('='*80+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddfa6a0ff1d8881cf4bd5285987ebc86797f87d694dadfd66bf5c6611ba202ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
