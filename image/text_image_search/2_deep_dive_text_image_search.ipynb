{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2218b66",
   "metadata": {},
   "source": [
    "# Deep Dive into Text-Image Search Engine with Towhee\n",
    "\n",
    "In the [previous tutorial](./1_build_text_image_search_engine.ipynb), we built and prototyped a proof-of-concept image search engine. Now, let's feed it with large-scale image datasets, and deploy it as a micro-service with Towhee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b056f",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "First we need to install dependencies such as pymilvus, towhee, fastapi and opencv-python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca1652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip -q install pymilvus towhee fastapi opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba622fa5",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "There is a subset of the ImageNet dataset (100 classes, 10 images for each class) is used in this demo, and the dataset is available via [Github](https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip).  The dataset is same as our previous tutorial: \"[Build a Milvus powered Text-Image Search Engine in Minutes](./1_build_text_image_search_engine.ipynb)\", and to make things easy, we'll repeat the important code blocks below; if you have already downloaded data, please move on to next section.\n",
    "\n",
    "The dataset is organized as follows:\n",
    "- **train**: directory of candidate images;\n",
    "- **test**: directory of test images;\n",
    "- **reverse_image_search.csv**: a csv file containing an ***id***, ***path***, and ***label*** for each image;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72f0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "100  119M  100  119M    0     0  9808k      0  0:00:12  0:00:12 --:--:-- 15.4M\n"
     ]
    }
   ],
   "source": [
    "! curl -L https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip -O\n",
    "! unzip -q -o reverse_image_search.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769017c",
   "metadata": {},
   "source": [
    "To use the dataset for image search, let's first define a helper function:\n",
    "\n",
    "- **read_images(results)**: read images by image IDs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ff9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import towhee\n",
    "from towhee._types.image import Image\n",
    "\n",
    "df = pd.read_csv('reverse_image_search.csv')\n",
    "df.head()\n",
    "\n",
    "id_img = df.set_index('id')['path'].to_dict()\n",
    "def read_images(results):\n",
    "    imgs = []\n",
    "    for re in results:\n",
    "        path = id_img[re.id]\n",
    "        imgs.append(Image(cv2.imread(path), 'BGR'))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07d2d3",
   "metadata": {},
   "source": [
    "### Create a Milvus Collection\n",
    "\n",
    "Before getting started, please make sure you have [installed milvus](https://milvus.io/docs/v2.0.x/install_standalone-docker.md). Let's first create a `text_image_search` collection that uses the [L2 distance metric](https://milvus.io/docs/v2.0.x/metric.md#Euclidean-distance-L2) and an [IVF_FLAT index](https://milvus.io/docs/v2.0.x/index.md#IVF_FLAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f36afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "def create_milvus_collection(collection_name, dim):\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    \n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "    \n",
    "    fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='text image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":512}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414cfe20",
   "metadata": {},
   "source": [
    "## Making Our Text-Image Search Engine Production Ready\n",
    "\n",
    "To put the text-image search engine into production, we need to feed it with a large-scale dataset and deploy a microservice to accept incoming queries.\n",
    "\n",
    "### Optimize for large-scale dataset\n",
    "\n",
    "When the dataset becomes very large, as huge as tens of millions of images, it faces two significant problems:\n",
    "\n",
    "1. embedding feature extractor and Milvus data loading needs to be fast so that we can finish the search index in time;\n",
    "2. There are corrupted images or images with wrong formats in the dataset. It is impossible to clean up all such bad cases when the dataset is huge. So the data pipeline needs to be very robust to such exceptions.\n",
    "\n",
    "Towhee supports parallel execution to improve performance for large-scale datasets, and also has `exception_safe` execution mode to ensure system stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f12cf",
   "metadata": {},
   "source": [
    "### Improve Performance with Parallel Execution\n",
    "\n",
    "We are able to enable parallel execution by simply calling `set_parallel` within the pipeline. It tells towhee to process the data in parallel. Here is an example that enables parallel execution on a pipeline using CLIP model. It can be seen that the execution speed below is nearly four times faster than before. And note that please clean up the GPU cache before runing with parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe7ac7",
   "metadata": {},
   "source": [
    "We'll use a helper class to compute runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d02160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test timer: 2.40s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, name):\n",
    "        self._name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._interval = time.time() - self._start\n",
    "        print('%s: %.2fs'%(self._name, self._interval))\n",
    "        \n",
    "with Timer('test timer'): # a small test case for the timer\n",
    "    time.sleep(2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3fcfc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip_vit_b32 load: 295.80s\n",
      "clip_vit_b32+parallel load: 81.60s\n"
     ]
    }
   ],
   "source": [
    "collection = create_milvus_collection('test_clip_vit_b32', 512)\n",
    "with Timer('clip_vit_b32 load'):\n",
    "    ( \n",
    "        towhee.read_csv('reverse_image_search.csv')\n",
    "            .runas_op['id', 'id'](func=lambda x: int(x))\n",
    "            .image_decode['path', 'img']()\n",
    "            .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32', modality='image')\n",
    "            .tensor_normalize['vec', 'vec']()\n",
    "            .to_milvus['id', 'vec'](collection=collection, batch=100)\n",
    "    )\n",
    "    \n",
    "collection_parallel = create_milvus_collection('test_clip_vit_b32_parallel', 512)\n",
    "with Timer('clip_vit_b32+parallel load'):\n",
    "    ( \n",
    "        towhee.read_csv('reverse_image_search.csv')\n",
    "            .runas_op['id', 'id'](func=lambda x: int(x))\n",
    "            .set_parallel(4)\n",
    "            .image_decode['path', 'img']()\n",
    "            .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32', modality='image')\n",
    "            .tensor_normalize['vec', 'vec']()\n",
    "            .to_milvus['id', 'vec'](collection=collection_parallel, batch=100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c15f99",
   "metadata": {},
   "source": [
    "## Deploy as a Microservice\n",
    "\n",
    "The data pipeline used in our experiments can be converted to a function with `towhee.api` and `as_function()`, as it is presented in the [previous tutorial](./1_build_text_image_search_engine.ipynb). We can also convert the data pipeline into a RESTful API with `serve()`, it generates FastAPI services from towhee pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977b255",
   "metadata": {},
   "source": [
    "### Insert Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9119468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import towhee\n",
    "from fastapi import FastAPI\n",
    "from pymilvus import connections, Collection\n",
    "\n",
    "app = FastAPI()\n",
    "connections.connect(host='127.0.0.1', port='19530')\n",
    "milvus_collection = Collection('test_clip_vit_b32')\n",
    "\n",
    "@towhee.register(name='get_path_id')\n",
    "def get_path_id(path):\n",
    "    timestamp = int(time.time()*10000)\n",
    "    id_img[timestamp] = path\n",
    "    return timestamp\n",
    "\n",
    "@towhee.register(name='milvus_insert')\n",
    "class MilvusInsert:\n",
    "    def __init__(self, collection):\n",
    "        self.collection = collection\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        data = []\n",
    "        for iterable in args:\n",
    "            data.append([iterable])\n",
    "        mr = self.collection.insert(data)\n",
    "        self.collection.load()\n",
    "        return str(mr)\n",
    "\n",
    "with towhee.api['file']() as api:\n",
    "    app_insert = (\n",
    "        api.image_load['file', 'img']()\n",
    "        .save_image['img', 'path'](dir='tmp/images')\n",
    "        .get_path_id['path', 'id']()\n",
    "        .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32',modality='image')\n",
    "        .tensor_normalize['vec', 'vec']()\n",
    "        .milvus_insert[('id', 'vec'), 'res'](collection=milvus_collection)\n",
    "        .select['id', 'path']()\n",
    "        .serve('/insert', app)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752be964",
   "metadata": {},
   "source": [
    "### Search Matched Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f71ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with towhee.api['text']() as api:\n",
    "    app_search = (\n",
    "        api.image_text_embedding.clip['text', 'vec'](model_name='clip_vit_b32',modality='text')\n",
    "        .tensor_normalize['vec','vec']()\n",
    "        .milvus_search['vec', 'result'](collection=milvus_collection, limit=5)\n",
    "        .runas_op['result', 'res_file'](func=lambda res: str([id_img[x.id] for x in res]))\n",
    "        .select['res_file']()\n",
    "        .serve('/search', app)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f68ba",
   "metadata": {},
   "source": [
    "### Count Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3c56d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with towhee.api() as api:\n",
    "    app_count = (\n",
    "        api.map(lambda _: milvus_collection.num_entities)\n",
    "        .serve('/count', app)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd94e002",
   "metadata": {},
   "source": [
    "### Start Server\n",
    "\n",
    "Finally to start FastAPI, there are three services `/insert`, `/search` and `/count`, you can run the following commands to test:\n",
    "\n",
    "```bash\n",
    "# upload text and search\n",
    "$ curl -X POST \"http://0.0.0.0:8000/search\"  --data \"a white dog\"\n",
    "# upload an image and insert\n",
    "$ curl -X POST \"http://0.0.0.0:8000/insert\"  --data-binary @test/banana/n07753592_323.JPEG -H 'Content-Type: image/jpeg'\n",
    "# count the collection\n",
    "$ curl -X POST \"http://0.0.0.0:8000/count\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79781225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [21465]\n",
      "2022-06-01 14:52:17,273 - 8605226496 - server.py-server:75 - INFO: Started server process [21465]\n",
      "INFO:     Waiting for application startup.\n",
      "2022-06-01 14:52:17,274 - 8605226496 - on.py-on:45 - INFO: Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "2022-06-01 14:52:17,275 - 8605226496 - on.py-on:59 - INFO: Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "2022-06-01 14:52:17,276 - 8605226496 - server.py-server:206 - INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64892 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64905 - \"POST /insert HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64907 - \"POST /insert HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64909 - \"POST /count HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "2022-06-01 14:57:04,178 - 8605226496 - server.py-server:252 - INFO: Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "2022-06-01 14:57:04,283 - 8605226496 - on.py-on:64 - INFO: Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "2022-06-01 14:57:04,286 - 8605226496 - on.py-on:75 - INFO: Application shutdown complete.\n",
      "INFO:     Finished server process [21465]\n",
      "2022-06-01 14:57:04,287 - 8605226496 - server.py-server:85 - INFO: Finished server process [21465]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app=app, host='0.0.0.0', port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
